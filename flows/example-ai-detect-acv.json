[{"id":"dc2b46484141f051","type":"subflow","name":"Parse JPEG [TF]","info":"","category":"Tequ-API Client","in":[{"x":60,"y":100,"wires":[{"id":"955eeab05409cd61"}]}],"out":[{"x":1100,"y":600,"wires":[{"id":"03ba536e0dc79eeb","port":1}]}],"env":[{"name":"is_stream","type":"bool","value":"false","ui":{"type":"input","opts":{"types":["bool","env"]}}},{"name":"latitude","type":"num","value":"66.503059","ui":{"type":"input","opts":{"types":["num","env"]}}},{"name":"longitude","type":"num","value":"25.726967","ui":{"type":"input","opts":{"types":["num","env"]}}},{"name":"thumbnail","type":"bool","value":"true","ui":{"type":"input","opts":{"types":["bool","env"]}}},{"name":"width","type":"num","value":"50","ui":{"type":"input","opts":{"types":["num","bin","env"]}}},{"name":"height","type":"num","value":"50","ui":{"type":"input","opts":{"types":["num","env"]}}},{"name":"camera_serial","type":"str","value":"12345678"}],"meta":{"module":"tequ-parse-jpeg-tf","version":"0.0.1","author":"juha.autioniemi@lapinamk.fi","desc":"Parse JPEG image and add metadata.","license":"MIT"},"color":"#3FADB5","icon":"font-awesome/fa-picture-o","status":{"x":1100,"y":660,"wires":[{"id":"898429879305e246","port":0}]}},{"id":"2eb1056d16ac1fc6","type":"image-info","z":"dc2b46484141f051","name":"","x":210,"y":400,"wires":[["83e4ef6a35b0051d"]]},{"id":"83e4ef6a35b0051d","type":"exif","z":"dc2b46484141f051","name":"","mode":"normal","property":"payload","x":190,"y":460,"wires":[["71d80411eeec75ec"]]},{"id":"8521dc3a9bb265e4","type":"moment","z":"dc2b46484141f051","name":"","topic":"","input":"","inputType":"date","inTz":"ETC/UTC","adjAmount":0,"adjType":"days","adjDir":"add","format":"","locale":"en-US","output":"utc_timestamp","outputType":"msg","outTz":"Europe/Helsinki","x":240,"y":220,"wires":[["156dc7f50cf9ae02"]]},{"id":"156dc7f50cf9ae02","type":"moment","z":"dc2b46484141f051","name":"","topic":"","input":"utc_timestamp","inputType":"msg","inTz":"ETC/UTC","adjAmount":0,"adjType":"days","adjDir":"add","format":"YYYY-MM-DD HH:mm:ss","locale":"en-US","output":"local_timestamp","outputType":"msg","outTz":"Europe/Helsinki","x":240,"y":280,"wires":[["5e837e3f956424a5"]]},{"id":"5e837e3f956424a5","type":"moment","z":"dc2b46484141f051","name":"","topic":"","input":"utc_timestamp","inputType":"msg","inTz":"ETC/UTC","adjAmount":0,"adjType":"days","adjDir":"add","format":"x","locale":"en-US","output":"unix_timestamp","outputType":"msg","outTz":"ETC/UTC","x":240,"y":340,"wires":[["2eb1056d16ac1fc6"]]},{"id":"898429879305e246","type":"status","z":"dc2b46484141f051","name":"","scope":["03ba536e0dc79eeb"],"x":820,"y":660,"wires":[[]]},{"id":"98e82be483a95bdd","type":"function","z":"dc2b46484141f051","name":"Reformat data","func":"let type;\nlet random_name = uuid.v4();\nlet image_type = msg.type;\nlet file_extension;\nlet latitude = Number(env.get(\"latitude\"))\nlet longitude = Number(env.get(\"longitude\"))\nlet unix_timestamp = parseInt(msg.unix_timestamp);\nlet serial;\n\ntry{\n    serial = (msg.exif.image.ImageDescription).split(\"_\")[1];\n}\ncatch(e){\n    env.get(\"camera_serial\")\n}\n\nlet datasource = serial;\n\nif (image_type == \"jpg\") {\n    image_type = \"image/jpeg\"\n    file_extension = \".jpg\"\n}\nelse if (image_type == \"png\") {\n    image_type = \"image/png\"\n    file_extension = \".png\"\n}\n\nmsg.topic = serial;\nmsg.datasource = serial;\nmsg.random_name = random_name;\nmsg.file_extension = file_extension;\n\nlet parameters = {};\ntry { parameters.owner = msg.exif.image.Copyright; } catch (e) { }\ntry { parameters.version = msg.exif.image.Software;} catch (e) { }\ntry { parameters.model = msg.exif.image.model; } catch (e) { }\ntry { parameters.manufacturer = msg.exif.image.Make; } catch (e) { }\ntry { \n    parameters.serial = msg.exif.image.Serial; \n}\ncatch (e) {\n    parameters.serial = env.get(\"camera_serial\"); \n}    \n\nmsg.data = {\n    \"type\": \"Feature\",\n    \"geometry\": {\n        \"type\": \"Point\",\n        \"coordinates\": [longitude, latitude]\n    },\n    \"properties\": {\n        \"datasource\": datasource,\n        \"local_timestamp\": msg.local_timestamp,\n        \"utc_timestamp\": msg.utc_timestamp,\n        \"unix_timestamp\": unix_timestamp,\n        \"cos\": {\n            \"bucket\": \"\",\n            \"region\": \"\",\n            \"service_id\": \"\"\n        },\n        \"object\": {\n            \"type\": image_type,\n            \"data\": {\n                \"width\": msg.width,\n                \"height\": msg.height,\n                \"size\": (msg.payload).length,\n                \"exif\": msg.exif,\n                \"parameters\": parameters,\n                \"original\": {\n                    \"image\": (msg.payload).toString('base64'),\n                    \"objectname\": datasource + \"-\" + random_name + file_extension,\n                    \"thumbnail\": (msg.thumbnail).toString('base64'),\n                    \"thumbnail_ms\": msg.thumbnail_ms,\n                    \"mjpeg_process_ms\":0\n                },\n                \"annotated\": {\n                    \"image\": \"\",\n                    \"objectname\": datasource + \"-\" + random_name+ \"_annotated\"+file_extension,\n                    \"thumbnail\": \"\",\n                    \"thumbnail_ms\":0,\n                    \"annotation_ms\":0,\n                    \"total_ms\":0\n                }\n            }\n        },\n        \"computer_vision\": {\n            \"type\": \"\",\n            \"model\": \"\",\n            \"inference_time\": \"\",\n            \"result\": \"\"\n        }\n    }\n}\n\ndelete msg.settings;\ndelete msg.width;\ndelete msg.height;\ndelete msg.type;\ndelete msg.exif;\ndelete msg.thumbnail;\ndelete msg.utc_timestamp;\ndelete msg.local_timestamp;\ndelete msg.unix_timestamp;\ndelete msg.start;\ndelete msg.thumbnail_ms;\ndelete msg.datasource;\ndelete msg.random_name;\ndelete msg.file_extension;\n\n\nreturn msg;","outputs":1,"noerr":0,"initialize":"","finalize":"","libs":[{"var":"uuid","module":"uuid"}],"x":840,"y":520,"wires":[["dcd82181b79268fa"]]},{"id":"71d80411eeec75ec","type":"change","z":"dc2b46484141f051","name":"timer","rules":[{"t":"set","p":"start","pt":"msg","to":"","tot":"date"}],"action":"","property":"","from":"","to":"","reg":false,"x":350,"y":460,"wires":[["47ad959e399127ee"]]},{"id":"a29e56924f3c4b62","type":"change","z":"dc2b46484141f051","name":"end timer","rules":[{"t":"set","p":"thumbnail_ms","pt":"msg","to":"$millis() - msg.start","tot":"jsonata"}],"action":"","property":"","from":"","to":"","reg":false,"x":820,"y":460,"wires":[["98e82be483a95bdd"]]},{"id":"f2fcd32368f15a5a","type":"change","z":"dc2b46484141f051","name":"timer","rules":[{"t":"set","p":"process_start","pt":"msg","to":"","tot":"date"}],"action":"","property":"","from":"","to":"","reg":false,"x":490,"y":140,"wires":[["8521dc3a9bb265e4"]]},{"id":"dcd82181b79268fa","type":"change","z":"dc2b46484141f051","name":"end timer","rules":[{"t":"set","p":"data.properties.object.data.original.mjpeg_process_ms","pt":"msg","to":"$millis() - msg.process_start","tot":"jsonata"},{"t":"delete","p":"process_start","pt":"msg"}],"action":"","property":"","from":"","to":"","reg":false,"x":820,"y":580,"wires":[["03ba536e0dc79eeb"]]},{"id":"fd80c13b0ff9de2b","type":"split","z":"dc2b46484141f051","name":"","splt":"[255, 216, 255]","spltType":"bin","arraySplt":1,"arraySpltType":"len","stream":true,"addname":"","x":370,"y":80,"wires":[["c0640f9b19b6ea45"]]},{"id":"c0640f9b19b6ea45","type":"function","z":"dc2b46484141f051","name":"Join","func":"let header = Buffer.from(msg.parts.ch);\nlet image = Buffer.from(msg.payload);\nlet arr = [header,image]\nmsg.payload = Buffer.concat(arr)\nreturn msg;","outputs":1,"noerr":0,"initialize":"","finalize":"","libs":[],"x":490,"y":80,"wires":[["f2fcd32368f15a5a"]]},{"id":"03ba536e0dc79eeb","type":"msg-speed","z":"dc2b46484141f051","name":"images","frequency":"sec","interval":1,"estimation":false,"ignore":false,"pauseAtStartup":false,"topicDependent":false,"x":980,"y":580,"wires":[[],[]]},{"id":"955eeab05409cd61","type":"switch","z":"dc2b46484141f051","name":"is_stream?","property":"is_stream","propertyType":"env","rules":[{"t":"true"},{"t":"else"}],"checkall":"true","repair":false,"outputs":2,"x":210,"y":100,"wires":[["fd80c13b0ff9de2b"],["f2fcd32368f15a5a"]]},{"id":"47ad959e399127ee","type":"function","z":"dc2b46484141f051","name":"Create thumbnail","func":"async function resize(inputTensor, width, height) {\n    return tf.tidy(() => {\n        let resized = tf.image.resizeBilinear(inputTensor, [height, width])\n        resized = tf.reshape(resized, [height, width, 3])\n        return Promise.resolve(tf.node.encodeJpeg(resized));\n    });\n}\n\nasync function convert(input) {\n    return tf.tidy(() => {\n        const tensor = tf.node.decodeJpeg(input, 3).expandDims(0);\n        const shape = tensor.shape;\n        return tensor\n    });\n}\n\ntry{\n    let thumbnail_time_ms;\n    const image = msg.payload;\n    const start = Date.now();\n    const width = env.get(\"width\")\n    const height = env.get(\"height\")\n    const tensor = await convert(image)\n    const thumbnail = Buffer.from(await resize(tensor, width, height))\n    msg.thumbnail = thumbnail\n    thumbnail_time_ms = Date.now() - start;\n    msg.thumbnail_ms = thumbnail_time_ms;\n    node.status({ fill: \"green\", shape: \"dot\", text: thumbnail_time_ms + \" ms\" });\n    return msg;\n}\ncatch (e) {\n    node.warn(e)\n    node.status({ fill: \"red\", shape: \"dot\", text: \"Convert failed...\" });\n    node.error(\"Resizing failed. Probably input is not an image buffer.\", msg);\n}","outputs":1,"noerr":0,"initialize":"","finalize":"// Code added here will be run when the\n// node is being stopped or re-deployed.\nconst model = context.get(\"savedmodel\")\ntf.dispose(model)\ncontext.set(\"model\", undefined)\ncontext.set(\"modelInfo\", undefined)","libs":[{"var":"tf","module":"@tensorflow/tfjs-node-gpu"}],"x":550,"y":460,"wires":[["a29e56924f3c4b62"]]},{"id":"4e11b7ba67d55a6b","type":"subflow","name":"[IMG] Annotate [TF]","info":"","category":"Tequ-API Client","in":[{"x":140,"y":140,"wires":[{"id":"d7a726cdc1ba008c"}]}],"out":[{"x":920,"y":140,"wires":[{"id":"9071309af7a7291a","port":0}]},{"x":460,"y":80,"wires":[{"id":"d7a726cdc1ba008c","port":0}]}],"env":[{"name":"box_colors","type":"json","value":"{\"fish\":\"#FFFFFF\",\"pike\":\"#006400\",\"perch\":\"#008000\",\"smolt\":\"#ADD8E6\",\"salmon\":\"#0000FF\",\"trout\":\"#0000FF\",\"cyprinidae\":\"#808080\",\"zander\":\"#009000\",\"bream\":\"#008800\"}","ui":{"type":"input","opts":{"types":["json"]}}},{"name":"image_settings","type":"json","value":"{\"quality\":0.8}","ui":{"type":"input","opts":{"types":["json"]}}},{"name":"image_type","type":"str","value":"image/jpeg","ui":{"type":"select","opts":{"opts":[{"l":{"en-US":"JPG"},"v":"image/jpeg"},{"l":{"en-US":"PNG"},"v":"image/png"}]}}},{"name":"bbox_lineWidth","type":"num","value":"5","ui":{"type":"spinner","opts":{"min":0,"max":10}}},{"name":"bbox_text_color","type":"str","value":"white","ui":{"type":"select","opts":{"opts":[{"l":{"en-US":"white"},"v":"white"},{"l":{"en-US":"black"},"v":"black"},{"l":{"en-US":"blue"},"v":"blue"},{"l":{"en-US":"green"},"v":"green"},{"l":{"en-US":"yellow"},"v":"yellow"},{"l":{"en-US":"red"},"v":"red"},{"l":{"en-US":"orange"},"v":"orange"}]}}},{"name":"bbox_font","type":"str","value":"30px Arial","ui":{"type":"select","opts":{"opts":[{"l":{"en-US":"5px Arial"},"v":"5 px Arial"},{"l":{"en-US":"10px Arial"},"v":"10px Arial"},{"l":{"en-US":"15px Arial"},"v":"15px Arial"},{"l":{"en-US":"20px Arial"},"v":"20px Arial"},{"l":{"en-US":"25px Arial"},"v":"25px Arial"},{"l":{"en-US":"30px Arial"},"v":"30px Arial"},{"l":{"en-US":"35px Arial"},"v":"35px Arial"},{"l":{"en-US":"40px Arial"},"v":"40px Arial"},{"l":{"en-US":"45px Arial"},"v":"45px Arial"},{"l":{"en-US":"50px Arial"},"v":"50px Arial"}]}}},{"name":"label_offset_x","type":"num","value":"0","ui":{"type":"input","opts":{"types":["num"]}}},{"name":"label_offset_y","type":"num","value":"30","ui":{"type":"input","opts":{"types":["num"]}}},{"name":"threshold","type":"num","value":"0.75","ui":{"type":"spinner","opts":{"min":0,"max":1}}},{"name":"width","type":"num","value":"50","ui":{"type":"input","opts":{"types":["num","env"]}}},{"name":"height","type":"num","value":"50","ui":{"type":"input","opts":{"types":["num","env"]}}}],"meta":{"module":"[IMG] Annotate [TF]","version":"0.0.1","author":"juha.autioniemi@lapinamk.fi","desc":"Annotates prediction results from [AI] Detect subflows.","license":"MIT"},"color":"#87A980","icon":"font-awesome/fa-pencil-square-o","status":{"x":920,"y":200,"wires":[{"id":"1267cc4998d8726c","port":0}]}},{"id":"d7a726cdc1ba008c","type":"function","z":"4e11b7ba67d55a6b","name":"Annotate with  canvas","func":"const start_ms = Date.now();\nconst img = msg.payload;\nconst objects = msg.data.properties.computer_vision.result\nconst labels = msg.data.properties.computer_vision.labels\n\nconst image_type = env.get(\"image_type\");\nconst image_settings = env.get(\"image_settings\");\nconst bbox_lineWidth = env.get(\"bbox_lineWidth\");\nconst bbox_text_color = env.get(\"bbox_text_color\");\nconst label_offset_x = env.get(\"label_offset_x\");\nconst label_offset_y = env.get(\"label_offset_y\");\nconst bbox_font = env.get(\"bbox_font\");\nconst COLORS = env.get(\"box_colors\");\n\n//Define threshold\nlet threshold = 0;\n\nconst global_settings = global.get(\"settings\") || undefined\nlet thresholdType = \"\"\n\nif(global_settings !== undefined){\n    if(\"threshold\" in global_settings){\n        threshold = global_settings[\"threshold\"]\n        thresholdType = \"global\";\n    }\n}\n\nelse if(\"threshold\" in msg){\n    threshold = msg.threshold;\n    thresholdType = \"msg\";\n    if(threshold < 0){\n        threshold = 0\n    }\n    else if(threshold > 1){\n        threshold = 1\n    }\n}\n\nelse{\n    threshold = env.get(\"threshold\");\n    thresholdType = \"env\";\n}\n\nmsg.thresholdUsed = threshold;\nmsg.thresholdTypeUsed = thresholdType;\n\nasync function annotateImage(image) {\n  const localImage = await canvas.loadImage(image);  \n  const cvs = canvas.createCanvas(localImage.width, localImage.height);\n  const ctx = cvs.getContext('2d');  \n  ctx.drawImage(localImage, 0, 0); \n  \n  objects.forEach((obj) => {\n        if(labels.includes(obj.class) && obj.score >= threshold){\n            let [x, y, w, h] = obj.bbox;\n            ctx.lineWidth = bbox_lineWidth;\n            ctx.strokeStyle = COLORS[obj.class];\n            ctx.strokeRect(x, y, w, h);\n            ctx.fillStyle = bbox_text_color;\n            ctx.font = bbox_font;\n            ctx.fillText(obj.class+\" \"+Math.round(obj.score*100)+\" %\",x+label_offset_x,y+label_offset_y);\n        }\n      });\n  \n  return cvs.toBuffer(image_type, image_settings);\n}\n\nlet diff_ms = start_ms - Date.now()\nmsg.data.properties.object.data.annotated.annotation_ms = diff_ms\n\nif(objects.length > 0){\n    msg.data.properties.object.data.annotated.image = await annotateImage(img)   \n    msg.objects_found = true\n    //msg.payload.annotation.objects_found = true\n    node.status({fill:\"green\",shape:\"dot\",text:diff_ms+\" ms\"});\n}\nelse{\n    msg.objects_found = false\n    //msg.payload.annotation.objects_found = false\n    node.status({ fill: \"red\", shape: \"dot\", text: \"No objects to annotate\"});\n}\n\ndelete msg.thresholdUsed;\ndelete msg.start;\ndelete msg.thresholdTypeUsed;\nreturn msg;","outputs":1,"noerr":0,"initialize":"","finalize":"","libs":[{"var":"canvas","module":"canvas"}],"x":300,"y":140,"wires":[["9071309af7a7291a"]]},{"id":"1267cc4998d8726c","type":"status","z":"4e11b7ba67d55a6b","name":"","scope":null,"x":340,"y":200,"wires":[[]]},{"id":"9071309af7a7291a","type":"function","z":"4e11b7ba67d55a6b","name":"Create thumbnail","func":"async function resize(inputTensor, width, height) {\n    return tf.tidy(() => {\n        let resized = tf.image.resizeBilinear(inputTensor, [height, width])\n        resized = tf.reshape(resized, [height, width, 3])\n        return Promise.resolve(tf.node.encodeJpeg(resized));\n    });\n}\n\nasync function convert(input) {\n    return tf.tidy(() => {\n        const tensor = tf.node.decodeJpeg(input, 3).expandDims(0);\n        const shape = tensor.shape;\n        return tensor\n    });\n}\n\ntry{   \n    if(msg.objects_found){\n        let thumbnail_time_ms;\n        const image = msg.data.properties.object.data.annotated.image;\n        const start = Date.now();\n        const width = env.get(\"width\")\n        const height = env.get(\"height\")\n        const tensor = await convert(image)\n        const thumbnail = Buffer.from(await resize(tensor, width, height))\n        msg.data.properties.object.data.annotated.thumbnail = thumbnail\n        thumbnail_time_ms = Date.now() - start;\n        msg.data.properties.object.data.annotated.thumbnail_ms = thumbnail_time_ms;\n        node.status({ fill: \"green\", shape: \"dot\", text: thumbnail_time_ms + \" ms\" });\n    }\n    return msg;\n}\ncatch (e) {\n    node.warn(e)\n    node.status({ fill: \"red\", shape: \"dot\", text: \"Convert failed...\" });\n    node.error(\"Resizing failed. Probably input is not an image buffer.\", msg);\n}","outputs":1,"noerr":0,"initialize":"","finalize":"// Code added here will be run when the\n// node is being stopped or re-deployed.\nconst model = context.get(\"savedmodel\")\ntf.dispose(model)\ncontext.set(\"model\", undefined)\ncontext.set(\"modelInfo\", undefined)","libs":[{"var":"tf","module":"@tensorflow/tfjs-node-gpu"}],"x":710,"y":140,"wires":[[]]},{"id":"f5489383c48b7546","type":"subflow","name":"[AI] Detect-acv","info":"Make prediction on image with Tensorflow.js model trained and exported from Microsoft Azure Custom Vision.\n\nInput image must be image buffer in **'msg.payload'**.\n\nModel is loaded from configured folder.\n\nInference image and add result to output message. \n\nTo train and exmport a model, please look:\n\nhttps://www.customvision.ai/\n","category":"Tequ-API Client","in":[{"x":80,"y":80,"wires":[{"id":"4a3260e906997fa4"}]}],"out":[{"x":700,"y":80,"wires":[{"id":"b2e07a6cce1a9b6e","port":0}]}],"env":[{"name":"model_folder","type":"str","value":"C:\\Users\\juha.autioniemi\\.node-red\\test","ui":{"type":"input","opts":{"types":["str"]}}},{"name":"threshold","type":"num","value":"0.50","ui":{"type":"spinner","opts":{"min":0,"max":1}}},{"name":"model_id","type":"str","value":"tequ-hissitproto-v1"}],"meta":{"module":"node-red-tequ-ai-detect-acv","version":"0.0.1","author":"juha.autioniemi@lapinamk.fi","desc":"Make prediction on image with Tensorflow.js model trained in Microsoft Azure Custom Vision service.","license":"MIT"},"color":"#FFCC66","icon":"node-red/status.svg","status":{"x":700,"y":140,"wires":[{"id":"e220d68131d1bea3","port":0}]}},{"id":"b2e07a6cce1a9b6e","type":"function","z":"f5489383c48b7546","name":"customvision","func":"let start = Date.now();\nvar imageBuffer = msg.payload;\nvar results = [];\nvar labels = context.get(\"labels\");\nvar threshold = msg.threshold;\nlet image_width = msg.data.properties.object.data.width;\nlet image_height = msg.data.properties.object.data.height;\nvar newResult;\nvar result_message;\n\n//Make prediction on input image\nlet model = context.get(\"model\")\nlet result = await model.executeAsync(imageBuffer);\n\nlet end = Date.now();\nlet diff = end - start;\n\n//Map result to JSON and connect label names\nvar bboxes = result[0];\nvar scores = result[1];\nvar label_idxs = result[2];\n\nfor(var i=0;i<bboxes.length;i++){\n    if(scores[i] >= threshold){\n        newResult = {\n            \"bbox\":[\n                bboxes[i][0] * image_width,\n                bboxes[i][1] * image_height,\n                (bboxes[i][2] - bboxes[i][0]) * image_width,\n                (bboxes[i][3] - bboxes[i][1]) * image_height\n            ],\n            \"class\":labels[label_idxs[i]],\n            \"label\":labels[label_idxs[i]],\n            \"score\":scores[i]\n        }\n        results.push(newResult)\n    }\n}\n\nmsg.data.properties.computer_vision.result = results;\nmsg.data.properties.computer_vision.type = \"object detection\";\nmsg.data.properties.computer_vision.threshold = threshold;\nmsg.data.properties.computer_vision.inference_time = diff;\nmsg.data.properties.computer_vision.model = env.get(\"model_id\");\nmsg.data.properties.computer_vision.metadata = context.get(\"metadata\");\nmsg.data.properties.computer_vision.manifest = context.get(\"manifest\");\nmsg.data.properties.computer_vision.labels = context.get(\"labels\");\nmsg.payload = imageBuffer;\nnode.status({ fill: \"blue\", shape: \"dot\", text: diff + \" ms\" });  \nreturn msg;","outputs":1,"noerr":0,"initialize":"// Code added here will be run once\n// whenever the node is started.\nconst platform = os.platform()\nnode.warn(platform)\nlet model_folder;\nlet manifest_file;\nlet LabelFileName;\nlet ModelFileName;\nlet MetadataPropsFileName;\nlet labelArray;\n\nif(platform == \"win32\"){\n    model_folder = env.get(\"model_folder\")\n    manifest_file = model_folder+\"\\\\\"+\"cvexport.manifest\"\n}\nelse{\n    model_folder = env.get(\"model_folder\")\n    manifest_file = model_folder+\"/\"+\"cvexport.manifest\"\n}\n\nif (context.get(\"model\") === undefined) {\n    try {\n        context.set(\"manifest\",JSON.parse(fs.readFileSync(manifest_file, 'utf8')))\n    } catch (err) {\n        node.error(err)\n    }\n}\n\nif(platform == \"win32\"){\n    LabelFileName           = model_folder+\"\\\\\"+context.get(\"manifest\")[\"LabelFileName\"]\n    ModelFileName           = \"file://\"+model_folder+\"\\\\\"+\"model.json\"\n    MetadataPropsFileName   = model_folder+\"\\\\\"+context.get(\"manifest\")[\"MetadataPropsFileName\"]\n}\nelse{\n    LabelFileName           = model_folder+\"/\"+context.get(\"manifest\")[\"LabelFileName\"]\n    ModelFileName           = \"file://\"+model_folder+\"/\"+\"model.json\"\n    MetadataPropsFileName   = model_folder+\"/\"+context.get(\"manifest\")[\"MetadataPropsFileName\"]\n}\n\n//node.warn(LabelFileName)\n//node.warn(ModelFileName)\n//node.warn(MetadataPropsFileName)\n\nif (context.get(\"labels\") === undefined) {\n    try {\n        var labels = fs.readFileSync(LabelFileName, 'utf8')\n        labelArray = labels.split(\"\\n\")\n        context.set(\"labels\",labelArray)\n        \n    } catch (err) {\n        node.warn(err)\n        node.error(\"Error reading labels: \"+err.message,err)\n    }\n}\n\nif (context.get(\"metadata\") === undefined) {\n    try {\n        context.set(\"metadata\",JSON.parse(fs.readFileSync(MetadataPropsFileName, 'utf8')))\n    } catch (err) {\n        node.error(\"Error reading metadata: \"+err.message,err)\n    }\n}\n\nif (context.get(\"model\") === undefined) {\n    try {\n        node.status({fill:\"green\",shape:\"dot\",text:\"Loading model...\"});\n        const model = new microsoftCustomvisionTfjsNode.ObjectDetectionModel();\n        await model.loadModelAsync(ModelFileName);\n        context.set(\"model\", model)\n        node.status({fill:\"green\",shape:\"dot\",text:\"Object detection ready.\"});\n    } catch (err) {\n        node.status({fill:\"red\",shape:\"dot\",text:err});\n        node.error(\"Error reading model: \" + err.message, err)\n    }\n}\n\n//node.warn(tf.getBackend())\n","finalize":"","libs":[{"var":"microsoftCustomvisionTfjsNode","module":"@microsoft/customvision-tfjs-node"},{"var":"fs","module":"fs"},{"var":"os","module":"os"}],"x":550,"y":80,"wires":[[]]},{"id":"c43ad9454285328e","type":"function","z":"f5489383c48b7546","name":"Set threshold","func":"//Define threshold\nvar threshold = 0;\n\nlet global_settings = global.get(\"settings\") || undefined\nvar thresholdType = \"\"\n\nif(global_settings !== undefined){\n    if(\"threshold\" in global_settings){\n        threshold = global_settings[\"threshold\"]\n        thresholdType = \"global\";\n    }\n}\n\nelse if(\"threshold\" in msg){\n    threshold = msg.threshold;\n    thresholdType = \"msg\";\n    if(threshold < 0){\n        threshold = 0\n    }\n    else if(threshold > 1){\n        threshold = 1\n    }\n}\n\nelse{\n    try{\n        threshold = env.get(\"threshold\");\n        thresholdType = \"env\";\n    }\n    catch(err){\n        threshold = 0.5\n        thresholdType = \"default\";\n    }\n}\n\nif(threshold == undefined){\n    threshold = 0\n}\n\nmsg.thresholdType = thresholdType;\nmsg.threshold = threshold;\n//node.status({fill:\"green\",shape:\"dot\",text:\"threshold: \"+threshold+\" | Image width: \"+image_width_cm});\nreturn msg;","outputs":1,"noerr":0,"initialize":"","finalize":"","libs":[],"x":370,"y":80,"wires":[["b2e07a6cce1a9b6e"]]},{"id":"4a3260e906997fa4","type":"function","z":"f5489383c48b7546","name":"isBuffer?","func":"let timestamp = new Date().toISOString();\nvar image = msg.payload;\n\nif(Buffer.isBuffer(image)){\n    //node.status({fill:\"green\",shape:\"dot\",text:timestamp + \" OK\"});  \n    return msg;\n}\nelse{\n    node.error(\"msg.payload is not an image buffer\",msg)\n    node.status({fill:\"red\",shape:\"dot\",text:timestamp + \" msg.payload is not an image buffer\"});  \n}","outputs":1,"noerr":0,"initialize":"","finalize":"","libs":[],"x":200,"y":80,"wires":[["c43ad9454285328e"]]},{"id":"e220d68131d1bea3","type":"status","z":"f5489383c48b7546","name":"","scope":["b2e07a6cce1a9b6e","70f48281642455fa"],"x":560,"y":140,"wires":[[]]},{"id":"7b248573a2bd55b0","type":"tab","label":"Flow 9","disabled":false,"info":"","env":[]},{"id":"7c0e65c7e9eee788","type":"subflow:f5489383c48b7546","z":"7b248573a2bd55b0","name":"","env":[{"name":"model_folder","value":"C:\\Users\\juha.autioniemi\\.node-red\\customvision","type":"str"},{"name":"threshold","value":"0.1","type":"num"},{"name":"image_width_cm","value":"100","type":"num"}],"x":520,"y":160,"wires":[["13ae01d7fbd105ae","aedcd756d4262c2e"]]},{"id":"13ae01d7fbd105ae","type":"debug","z":"7b248573a2bd55b0","name":"debug 68","active":true,"tosidebar":true,"console":false,"tostatus":false,"complete":"true","targetType":"full","statusVal":"","statusType":"auto","x":700,"y":120,"wires":[]},{"id":"2adcd2b76e7105fb","type":"fileinject","z":"7b248573a2bd55b0","name":"","x":120,"y":160,"wires":[["6cbef0c4aae025a4"]]},{"id":"852422f1cf61d8a5","type":"image","z":"7b248573a2bd55b0","name":"","width":"720","data":"data.properties.object.data.annotated.image","dataType":"msg","thumbnail":false,"active":true,"pass":false,"outputs":0,"x":720,"y":240,"wires":[]},{"id":"eec0522fa5bdbb33","type":"debug","z":"7b248573a2bd55b0","name":"debug 69","active":true,"tosidebar":true,"console":false,"tostatus":false,"complete":"true","targetType":"full","statusVal":"","statusType":"auto","x":940,"y":140,"wires":[]},{"id":"aedcd756d4262c2e","type":"subflow:4e11b7ba67d55a6b","z":"7b248573a2bd55b0","name":"","env":[{"name":"box_colors","value":"{\"tuolihissi\":\"#008800\"}","type":"json"},{"name":"bbox_lineWidth","value":"4","type":"num"},{"name":"bbox_text_color","value":"green","type":"str"},{"name":"threshold","value":"0.1","type":"num"}],"x":730,"y":160,"wires":[["852422f1cf61d8a5","eec0522fa5bdbb33"],[]]},{"id":"6cbef0c4aae025a4","type":"subflow:dc2b46484141f051","z":"7b248573a2bd55b0","name":"","x":310,"y":160,"wires":[["7c0e65c7e9eee788","19e0404aa868ddef"]]},{"id":"19e0404aa868ddef","type":"debug","z":"7b248573a2bd55b0","name":"debug 70","active":true,"tosidebar":true,"console":false,"tostatus":false,"complete":"true","targetType":"full","statusVal":"","statusType":"auto","x":500,"y":120,"wires":[]},{"id":"0f4ec576a97255c2","type":"catch","z":"7b248573a2bd55b0","name":"","scope":null,"uncaught":false,"x":220,"y":280,"wires":[["f826fa325ebcb9bb"]]},{"id":"f826fa325ebcb9bb","type":"debug","z":"7b248573a2bd55b0","name":"debug 71","active":true,"tosidebar":true,"console":false,"tostatus":false,"complete":"true","targetType":"full","statusVal":"","statusType":"auto","x":400,"y":280,"wires":[]}]
